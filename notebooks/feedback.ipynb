{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a404e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from mlblocks import MLPipeline\n",
    "from orion.data import load_signal\n",
    "from orion.analysis import _build_events_df\n",
    "from orion.evaluation import contextual_f1_score\n",
    "\n",
    "from sintel.actions import annotator, add_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe9930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "DATA_PATH = '../sintel/data/{}'\n",
    "\n",
    "UNSUPERVISED_PIPELINE_DIR = '../results/save_pipelines/{}'\n",
    "\n",
    "ANOMALIES = pd.read_csv(DATA_PATH.format('anomalies.csv'))\n",
    "\n",
    "UNSUPERVISED_PIPELINE = glob(UNSUPERVISED_PIPELINE_DIR.format('*.pkl'))\n",
    "\n",
    "BENCHMARK_DATA = pd.read_csv(\n",
    "    DATA_PATH.format('datasets.csv'), index_col=0, header=None).applymap(ast.literal_eval).to_dict()[1]\n",
    "\n",
    "\n",
    "INTERVAL = {\n",
    "    \"realTweets\": 300\n",
    "}\n",
    "\n",
    "INTERVAL_FMT = {\n",
    "    \"realTweets\": 3600\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a76154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anomalies(signal):\n",
    "    anomalies = ANOMALIES.set_index('signal').loc[signal].values[0]\n",
    "    anomalies = pd.DataFrame(json.loads(anomalies), columns=['start', 'end'])\n",
    "    return anomalies\n",
    "\n",
    "def _build_events(events):\n",
    "    events = pd.DataFrame(list(events), columns=['start', 'end'])\n",
    "    events['start'] = events['start'].astype(int)\n",
    "    events['end'] = events['end'].astype(int)\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def _merge_sequences(sequences):\n",
    "    if len(sequences) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    if not isinstance(sequences, list):\n",
    "        sequences = list(sequences[['start', 'end']].itertuples(index=False))\n",
    "\n",
    "    sorted_sequences = sorted(sequences, key=lambda entry: entry[0])\n",
    "    new_sequences = [sorted_sequences[0]]\n",
    "    weights = [sorted_sequences[0][1] - sorted_sequences[0][0]]\n",
    "\n",
    "    for sequence in sorted_sequences[1:]:\n",
    "        prev_sequence = new_sequences[-1]\n",
    "\n",
    "        if sequence[0] <= prev_sequence[1] + 1:\n",
    "            weights.append(sequence[1] - sequence[0])\n",
    "            new_sequences[-1] = (prev_sequence[0], max(prev_sequence[1], sequence[1]))\n",
    "\n",
    "        else:\n",
    "            weights = [sequence[1] - sequence[0]]\n",
    "            new_sequences.append(sequence)\n",
    "\n",
    "    return np.array(new_sequences)\n",
    "\n",
    "def _merge_events(first, second):\n",
    "    first = first.copy()[['start', 'end']]\n",
    "    second = second.copy()[['start', 'end']]\n",
    "    \n",
    "    events = pd.concat([first, second])\n",
    "    return _merge_sequences(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb14aa",
   "metadata": {},
   "source": [
    "### feedback experiment process\n",
    "\n",
    "1. use `lstm_dynamic_threshold` to find anomalies using unsupervised learning.\n",
    "2. use `simulation` to select a number of fp, fn to correct by the simulator in the train dataset:\n",
    "    - this selection can be weighted by severity score\n",
    "    - this selection can be random\n",
    "3. train the `lstm_supervised` pipeline on the annotated timeseries\n",
    "4. evaluate the performance on the test dataset.\n",
    "5. repeat step 2 - 4.\n",
    "\n",
    "**excluding**\n",
    "NASA dataset due to the fact that nasa dataset is a pre-split into (train: no anomalies, test: with anomalies), therefore, the simulation will need to be executed on the test dataset which is illogical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd25007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SMAP', 'MSL', 'YAHOOA1', 'YAHOOA2', 'YAHOOA3', 'YAHOOA4', 'artificialWithAnomaly', 'realAdExchange', 'realAWSCloudwatch', 'realTraffic', 'realTweets'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BENCHMARK_DATA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c79cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalies_in_test(anomalies, start):\n",
    "    df = anomalies.copy()\n",
    "    remove = []\n",
    "    for i, anom in df.iterrows():\n",
    "        if anom.start < start and anom.end > start:\n",
    "            df.at[i, 'start'] = start\n",
    "        elif anom.start < start:\n",
    "            remove.append(i)\n",
    "\n",
    "    return df.drop(remove)\n",
    "\n",
    "def get_anomalies_in_train(anomalies, start):\n",
    "    df = anomalies.copy()\n",
    "    remove = []\n",
    "    for i, anom in df.iterrows():\n",
    "        if anom.start < start and anom.end > start:\n",
    "            df.at[i, 'end'] = start\n",
    "        elif anom.start > start:\n",
    "            remove.append(i)\n",
    "\n",
    "    return df.drop(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "368de01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ec2_cpu_utilization_5f5533',\n",
       " 'ec2_cpu_utilization_24ae8d',\n",
       " 'ec2_cpu_utilization_53ea38',\n",
       " 'ec2_cpu_utilization_77c1ca',\n",
       " 'ec2_cpu_utilization_825cc2',\n",
       " 'ec2_cpu_utilization_ac20cd',\n",
       " 'ec2_cpu_utilization_c6585a',\n",
       " 'ec2_cpu_utilization_fe7f93',\n",
       " 'ec2_disk_write_bytes_1ef3de',\n",
       " 'ec2_disk_write_bytes_c0d644',\n",
       " 'ec2_network_in_5abac7',\n",
       " 'ec2_network_in_257a54',\n",
       " 'elb_request_count_8c0756',\n",
       " 'grok_asg_anomaly',\n",
       " 'iio_us-east-1_i-a2eb1cd9_NetworkIn',\n",
       " 'rds_cpu_utilization_cc0c53',\n",
       " 'rds_cpu_utilization_e47b3b')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "907b869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificialWithAnomaly\n",
      "test 5\n",
      "train 6\n",
      "\n",
      "realAWSCloudwatch\n",
      "test 10\n",
      "train 21\n",
      "\n",
      "realTweets\n",
      "test 6\n",
      "train 27\n",
      "\n",
      "realTraffic\n",
      "test 8\n",
      "train 7\n",
      "\n",
      "realAdExchange\n",
      "test 3\n",
      "train 9\n",
      "\n",
      "tot_test 32\n",
      "tot_train 70\n"
     ]
    }
   ],
   "source": [
    "data = ['artificialWithAnomaly', 'realAWSCloudwatch', 'realTweets', 'realTraffic', 'realAdExchange']\n",
    "\n",
    "# data = ['realAWSCloudwatch']\n",
    "\n",
    "check = ['grok_asg_anomaly',\n",
    "         'iio_us-east-1_i-a2eb1cd9_NetworkIn',\n",
    "         'rds_cpu_utilization_cc0c53',\n",
    "         'rds_cpu_utilization_e47b3b']\n",
    "\n",
    "tot_test = 0\n",
    "tot_train = 0\n",
    "for dataset in data:\n",
    "    print(dataset)\n",
    "    per_data_test = 0\n",
    "    per_data_train = 0\n",
    "    for signal in BENCHMARK_DATA[dataset]:\n",
    "#         if signal not in check:\n",
    "#             continue\n",
    "        \n",
    "        # data\n",
    "        data_path = DATA_PATH.format(signal + '.csv')\n",
    "        train, test = load_signal(data_path, test_size=0.3)\n",
    "        ground_truth = load_anomalies(signal)\n",
    "        \n",
    "        start = test['timestamp'].min()\n",
    "\n",
    "        # train \n",
    "        train_ground_truth = get_anomalies_in_train(ground_truth, start)\n",
    "\n",
    "        # test \n",
    "        test_ground_truth = get_anomalies_in_test(ground_truth, start)\n",
    "        \n",
    "        per_data_test += len(test_ground_truth)\n",
    "        per_data_train += len(train_ground_truth) # len(ground_truth) - len(test_ground_truth)\n",
    "\n",
    "    tot_test += per_data_test\n",
    "    tot_train += per_data_train\n",
    "    \n",
    "    print(\"test\", per_data_test)\n",
    "    print(\"train\", per_data_train)\n",
    "    print()\n",
    "    \n",
    "print(\"tot_test\", tot_test)\n",
    "print(\"tot_train\", tot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86557c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificialWithAnomaly\n",
    "test 5\n",
    "train 1\n",
    "\n",
    "realAWSCloudwatch\n",
    "test 10\n",
    "train 20\n",
    "\n",
    "realTweets\n",
    "test 6\n",
    "train 27\n",
    "\n",
    "realTraffic\n",
    "test 8\n",
    "train 6\n",
    "\n",
    "realAdExchange\n",
    "test 3\n",
    "train 8\n",
    "\n",
    "tot_test 29\n",
    "tot_train 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbed143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_path = '../results/supervised/{}.pkl'\n",
    "dataset = 'realTweets'\n",
    "\n",
    "for signal in BENCHMARK_DATA[dataset]:\n",
    "    print(signal)\n",
    "\n",
    "    # data\n",
    "    data_path = DATA_PATH.format(signal + '.csv')\n",
    "    timeseries = load_signal(data_path)\n",
    "    train, test = load_signal(data_path, test_size=0.3)\n",
    "    ground_truth = load_anomalies(signal)\n",
    "\n",
    "    # train\n",
    "    train['label'] = [0] * len(train)\n",
    "    train = train.set_index('timestamp').sort_index()  \n",
    "    train = train.reset_index()\n",
    "\n",
    "    # test\n",
    "    test['label'] = [0] * len(test)\n",
    "    test = test.set_index('timestamp').sort_index()  \n",
    "    test = test.reset_index()\n",
    "\n",
    "    # unsupervised\n",
    "\n",
    "    pipeline_path = [x for x in UNSUPERVISED_PIPELINE if signal in x][0]\n",
    "\n",
    "    with open(pipeline_path, 'rb') as pfile:\n",
    "        pipeline = pickle.load(pfile)\n",
    "\n",
    "    anomalies = pipeline.predict(timeseries)\n",
    "    anomalies = _build_events_df(anomalies)\n",
    "\n",
    "    start = test['timestamp'].min()\n",
    "\n",
    "    # train \n",
    "    train_anomalies = get_anomalies_in_train(anomalies, start)\n",
    "    train_ground_truth = get_anomalies_in_train(ground_truth, start)\n",
    "\n",
    "    # test \n",
    "    test_anomalies = get_anomalies_in_test(anomalies, start)\n",
    "    test_ground_truth = get_anomalies_in_test(ground_truth, start)\n",
    "\n",
    "    class_weights = {0: 1, 1: 1e3}\n",
    "    interval = INTERVAL[dataset]\n",
    "    interval_fmt = INTERVAL_FMT[dataset]\n",
    "\n",
    "    hyperparameters = {\n",
    "        \"mlprimitives.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
    "            \"interval\": interval,\n",
    "        },\n",
    "        \"keras.Sequential.LSTMTimeSeriesClassifier#1\": {\n",
    "            \"epochs\": 10,\n",
    "            'validation_split': 0.0,\n",
    "            'verbose': False\n",
    "        },\n",
    "        \"sintel.primitives.timeseries_anomalies.format_anomalies#1\": {\n",
    "            \"interval\": interval_fmt\n",
    "        }\n",
    "    }\n",
    "\n",
    "    supervised_pipeline = MLPipeline(\"lstm_supervised\")\n",
    "    supervised_pipeline.set_hyperparameters(hyperparameters)\n",
    "\n",
    "    # simulate annotation\n",
    "\n",
    "    k = 1\n",
    "    events = _merge_sequences(annotator(train_anomalies, train_ground_truth, k))\n",
    "    events = _build_events(events)\n",
    "    stop = contextual_f1_score(events, train_ground_truth, weighted=False) == 1.0\n",
    "\n",
    "    iteration = 1\n",
    "    while not stop:\n",
    "        train = train.set_index('timestamp').sort_index()\n",
    "        for _, a in events.iterrows():\n",
    "            train.at[a.start: a.end, 'label'] = 1\n",
    "\n",
    "        train = train.reset_index()\n",
    "        train.head()\n",
    "\n",
    "        supervised_pipeline.fit(train, class_weights=class_weights)\n",
    "\n",
    "        # train score\n",
    "        train_anomalies = supervised_pipeline.predict(train)\n",
    "        train_anomalies = _build_events(train_anomalies)\n",
    "\n",
    "        train_f1_score = contextual_f1_score(train_anomalies, train_ground_truth, weighted=False)\n",
    "\n",
    "        # test score\n",
    "        test_anomalies = supervised_pipeline.predict(test)\n",
    "        test_anomalies = _build_events(test_anomalies)\n",
    "\n",
    "        test_f1_score = contextual_f1_score(test_anomalies, test_ground_truth, weighted=False)\n",
    "\n",
    "        # display\n",
    "        print(\"train score: \", train_f1_score)\n",
    "        print(\"test score: \", test_f1_score)\n",
    "\n",
    "        events = _merge_sequences(annotator(train_anomalies, train_ground_truth, k))\n",
    "        events = _build_events(events)\n",
    "        stop = contextual_f1_score(events, train_ground_truth, weighted=False) == 1.0\n",
    "        \n",
    "        with open(save_path.format(dataset + '_' + signal + '_' + str(iteration)), 'wb') as f:\n",
    "            pickle.dump({\n",
    "                \"test_f1_score\": test_f1_score,\n",
    "                \"train_f1_score\": train_f1_score,\n",
    "                \"test_anomalies\": test_anomalies,\n",
    "                \"train_anomalies\": train_anomalies,\n",
    "                \"events\": events,\n",
    "                \"pipeline\": supervised_pipeline,\n",
    "            }, f)\n",
    "            \n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d8d5528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1425353873</td>\n",
       "      <td>1425472673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1426440173</td>\n",
       "      <td>1426523573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1427734973</td>\n",
       "      <td>1427817773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start         end\n",
       "0  1425353873  1425472673\n",
       "1  1426440173  1426523573\n",
       "2  1427734973  1427817773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39a55b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
